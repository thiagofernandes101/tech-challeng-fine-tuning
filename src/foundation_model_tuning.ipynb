{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78a0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiagofernandes101/projects/fiap/FineTunningTechChallenge/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from datasets import Dataset, Features, Value, load_dataset\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import html\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a14c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 1024\n",
    "dtype = None\n",
    "load_in_4bit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9deaa167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str):\n",
    "    # Your cleaning logic here\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r\"--.*\", \"\", text)\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a98619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(file_path: str):\n",
    "    training_data = []\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        buffer: str = \"\"\n",
    "        for line in file:\n",
    "            buffer += line.strip()\n",
    "            try:\n",
    "                item: dict = json.loads(buffer)\n",
    "                buffer: str = \"\"\n",
    "                title: str = clean_text(item.get(\"title\", \"\"))\n",
    "                content: str = clean_text(item.get(\"content\", \"\"))\n",
    "                if title and content:\n",
    "                    yield {\"title\": title, \"content\": content}\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb63a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_training(example: dict, tokenizer) -> dict:\n",
    "    title = example[\"title\"]\n",
    "    content = example[\"content\"]\n",
    "\n",
    "    # conversation = [\n",
    "    #     {'role': 'user', 'content': f'Write a piece in the style of a book titled \"{title}\".'},\n",
    "    #     {'role': 'assistant', 'content': content}\n",
    "    # ]\n",
    "    # formatted_text = tokenizer.apply_chat_template(conversation, tokenize=False, add_generation_prompt=False)\n",
    "    formatted_text = f\"### Title:\\n{title}\\n\\n### Content:\\n{content}\"\n",
    "    return {\"text\": formatted_text + tokenizer.eos_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bab92bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.5: Fast Llama patching. Transformers: 4.56.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060 Laptop GPU. Num GPUs = 1. Max memory: 6.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.9.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "fourbit_models = [\n",
    "    #\"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    #\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
    "    #\"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    #\"unsloth/gemma-2-9b-bnb-4bit\"\n",
    "]\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Phi-3.5-mini-instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1652951",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/thiagofernandes101/projects/fiap/FineTunningTechChallenge/datasets/trn.json\"\n",
    "streaming_dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\", streaming=True)\n",
    "filtered_dataset = streaming_dataset.filter(\n",
    "    lambda example: example.get(\"title\") and example.get(\"content\")\n",
    ")\n",
    "processed_dataset = filtered_dataset.map(\n",
    "    lambda example: format_for_training(example, tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdb4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    per_device_train_batch_size=2,  # Aumente se sua GPU permitir para acelerar\n",
    "    gradient_accumulation_steps=4, # Ajuste para manter um lote efetivo de 8 (2*4)\n",
    "    warmup_steps=5,\n",
    "    max_steps = 100, # Remova esta linha\n",
    "    # num_train_epochs=1, # Adicione esta linha para treinar em todo o dataset uma vez\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = processed_dataset, # Convert to iterable dataset\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    args = training_args,\n",
    "    packing = False, # Keep packing as it's efficient with streaming\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7129dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(title_for_testing):\n",
    "  # title_for_testing = \"Jane's Battleships of the 20th Century\"\n",
    "  message_for_testing = [\n",
    "      {\"role\": \"user\", \"content\": f'Tell me about the book \"{title_for_testing}\".'},\n",
    "  ]\n",
    "  input_ids = tokenizer.apply_chat_template(\n",
    "      message_for_testing,\n",
    "      tokenize=True,\n",
    "      add_generation_prompt=True, # This is crucial for inference\n",
    "      return_tensors=\"pt\"\n",
    "  ).to(\"cuda\")\n",
    "  outputs = model.generate(input_ids=input_ids, max_new_tokens=256, use_cache=True)\n",
    "  results = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "  print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfe6f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST (BEFORE) TRAINING ---\n",
      "Tell me about the book \"Jane's Battleships of the 20th Century\". \"Jane's Battleships of the 20th Century\" does not appear to be a widely recognized book or a well-known publication in the public domain as of my knowledge cutoff in 2023. It's possible that the book could be a niche or specialized publication, perhaps a work of historical interest or a fictional narrative.\n",
      "\n",
      "If you are looking for information on a specific topic related to battleships or naval history, I can certainly help with that. However, for specific details about the book in question, I would need more context or information.\n",
      "\n",
      "If you have more details or context about the book, please provide them, and I'll do my best to assist you. Given the lack of information about \"Jane's Battleships of the 20th Century,\" I can't provide a detailed summary or analysis of the book. However, I can offer a general overview of the historical context of battleships in the 20th century, which might be relevant to the book's themes.\n",
      "\n",
      "The 20th century was a period of significant change in naval warfare. The advent of new technologies, such as\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TEST (BEFORE) TRAINING ---\")\n",
    "test_model(\"Jane's Battleships of the 20th Century\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d2414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 32009}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o fine-tuning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 800 | Num Epochs = 9,223,372,036,854,775,807 | Total steps = 100\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 29,884,416 of 3,850,963,968 (0.78% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 07:14, Epoch 1/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.663700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.223900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.341800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.260500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.172000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando o fine-tuning...\")\n",
    "trainer_stats = trainer.train()\n",
    "print(\"Fine-tuning conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606315ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST (AFTER) TRAINING ---\n",
      "Tell me about the book \"Jane's Battleships of the 20th Century\". \"Jane's Battleships of the 20th Century\" is a comprehensive reference guide published by Jane's Information Group, a company known for its specialized military and defense publications. The book provides detailed information on battleships from the 20th century, including their design, armament, and operational history.\n",
      "\n",
      "The book is organized chronologically, with each entry providing a brief overview of the ship's history, followed by a more detailed description of its design, armament, and notable actions. The book also includes numerous illustrations, including photographs, drawings, and diagrams.\n",
      "\n",
      "\"Jane's Battleships of the 20th Century\" is an essential reference for anyone interested in naval history, maritime warfare, or military strategy. It is also a valuable resource for naval historians, military officers, and anyone with an interest in the history of naval warfare.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TEST (AFTER) TRAINING ---\")\n",
    "test_model(\"Jane's Battleships of the 20th Century\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
